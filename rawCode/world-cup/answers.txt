Times:

10 simulations: TODO (record time using 0m0.000s format)        0m0.020s
100 simulations: TODO (record time using 0m0.000s format)       0m0.020s
    Belgium: 24.0% chance of winning
    Brazil: 21.0% chance of winning
    Spain: 21.0% chance of winning
1000 simulations: TODO (record time using 0m0.000s format)      0m0.027s
    Belgium: 22.2% chance of winning
    Brazil: 21.2% chance of winning
    Portugal: 14.8% chance of winning
10000 simulations: TODO (record time using 0m0.000s format)     0m0.088s
    Belgium: 20.8% chance of winning
    Brazil: 20.5% chance of winning
    Portugal: 14.3% chance of winning
100000 simulations: TODO (record time using 0m0.000s format)    0m0.650s
    Belgium: 21.3% chance of winning
    Brazil: 20.8% chance of winning
    Portugal: 14.1% chance of winning
1000000 simulations: TODO (record time using 0m0.000s format)   0m6.899s
    Belgium: 21.1% chance of winning
    Brazil: 20.7% chance of winning
    Portugal: 14.2% chance of winning

Questions:

Which predictions, if any, proved incorrect as you increased the number of simulations?:
    The smaller number of simulations like 10 to 1000 required almost the same amount of time.


Suppose you're charged a fee for each second of compute time your program uses.
After how many simulations would you call the predictions "good enough"?:
    I would say 10000 is good enough and stablized compared to the previous lower number of sims,
    the jump in real time for 100000 and 1000000 is not worth while.
